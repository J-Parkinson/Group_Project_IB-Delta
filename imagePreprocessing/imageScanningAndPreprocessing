from tempfile import TemporaryDirectory

import cv2
import numpy as np
from cv2 import getStructuringElement, GaussianBlur, Canny, erode, cvtColor, \
    arcLength, COLOR_BGR2GRAY, approxPolyDP, CHAIN_APPROX_SIMPLE, dilate, imread, MORPH_RECT, contourArea, \
    findContours, RETR_LIST, imwrite
from imutils import resize, grab_contours
from numpy import array, zeros, greater, hsplit, vsplit, greater_equal, diff, delete, insert, int32
from scipy.ndimage import convolve1d
from scipy.signal import argrelextrema
# import the necessary packages
from skimage.filters import threshold_sauvola

# import fitz


''' orderPoints
    Calculates which of the four coordinates provided are which (TL, BR, TR, BL)
    Returns rect, with coords in CW direction, and the first coordinate being the top left coord'''


def orderPoints(pts):
    # initialzie a list of coordinates that will be ordered
    # such that the first entry in the list is the top-left,
    # the second entry is the top-right, the third is the
    # bottom-right, and the fourth is the bottom-left
    rect = np.zeros((4, 2), dtype="float32")

    # the top-left point will have the smallest sum, whereas
    # the bottom-right point will have the largest sum
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]

    # now, compute the difference between the points, the
    # top-right point will have the smallest difference,
    # whereas the bottom-left will have the largest difference
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]

    # return the ordered coordinates
    return rect


''' fourPointTransform
    Finds the points which we can pass to cv2.PerspectiveTransform/warpPerspective
    Returns warped image'''


def fourPointTransform(image, pts):
    # obtain a consistent order of the points and unpack them
    # individually
    rect = orderPoints(pts)
    (tl, tr, br, bl) = rect

    # compute the width of the new image, which will be the
    # maximum distance between bottom-right and bottom-left
    # x-coordiates or the top-right and top-left x-coordinates
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    # compute the height of the new image, which will be the
    # maximum distance between the top-right and bottom-right
    # y-coordinates or the top-left and bottom-left y-coordinates
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))

    # now that we have the dimensions of the new image, construct
    # the set of destination points to obtain a "birds eye view",
    # (i.e. top-down view) of the image, again specifying points
    # in the top-left, top-right, bottom-right, and bottom-left
    # order
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]], dtype="float32")

    # compute the perspective transform matrix and then apply it
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))

    # return the warped image
    return warped


''' normaliseImage
    Takes our original image, converts to greyscale, finds the contours of the page and performs a perspective transform on the original image'''


def normaliseImage(image, orig):
    # convert the image to grayscale, blur it, and find edges
    # in the image
    gray = cvtColor(image, COLOR_BGR2GRAY)
    gray = GaussianBlur(gray, (7, 7), 0)
    edged = Canny(gray, 75, 200)

    # find the contours in the edged image, keeping only the
    # largest ones, and initialize the screen contour
    first = (image.shape[0] // 100)
    second = ((image.shape[0] // 100)) // 2
    element = getStructuringElement(MORPH_RECT, (first // 2, first // 2), (second // 2, second // 2))
    edged = dilate(edged, element, iterations=3)
    edged = erode(edged, element, iterations=2)

    cnts = findContours(edged.copy(), RETR_LIST, CHAIN_APPROX_SIMPLE)

    cnts = grab_contours(cnts)
    cnts = sorted(cnts, key=contourArea, reverse=True)[:5]

    screenCnt = array([])

    # loop over the contours
    for c in cnts:
        # approximate the contour
        peri = arcLength(c, True)
        approx = approxPolyDP(c, 0.01 * peri, True)

        # if our approximated contour has four points, then we
        # can assume that we have found our screen
        if len(approx) == 4:
            screenCnt = approx
        break

    if (screenCnt.size != 0):

        # apply the four point transform to obtain a top-down
        # view of the original image
        transformed = fourPointTransform(orig, screenCnt.reshape(4, 2))

    else:
        transformed = orig

    # convert the warped image to grayscale, then threshold it
    # to give it that 'black and white' paper effect
    # also resize to try and increase fidelity of output

    transformed = resize(transformed, height=image.shape[0])
    transformed = cvtColor(transformed, COLOR_BGR2GRAY)
    threshold = threshold_sauvola(transformed, 11, 0.15)
    transformed = (transformed > threshold).astype("uint8") * 255

    return transformed


def findLinesandNormalise(source, dest):
    # load the image and compute the ratio of the old height
    # to the new height, clone it, and resize it
    image = imread(source)
    orig = image.copy()

    transformed = normaliseImage(image, orig)

    colLocations = calculateColumns(transformed)

    rowLocations = calculateRows(transformed)

    cells = splitIntoCells(transformed, rowLocations, colLocations)

    with TemporaryDirectory() as dir:
        for x, image in enumerate(cells):
            imwrite(dir + "/cell-" + str(x // len(colLocations)) + "-" + str(x % len(colLocations)) + ".png", image)

    return


def splitIntoCells(image, rows, cols):
    splitRows = vsplit(image, rows)

    return [a for b in [hsplit(row, cols) for row in splitRows] for a in b]


def calculateColumns(transformed):
    transformedsumx = transformed.sum(axis=0)
    threshold = transformedsumx.max() * 0.99
    columns = zeros(transformedsumx.shape)
    columns[transformedsumx < threshold] = 255
    columns = array(columns).astype(int)
    columns = convolve1d(convolve1d(columns, array([1, 1, 1, 3, 5, 8, 4, 3, 1, 1, 1]), mode="nearest"),
                         array([1, 1, 1, 3, 5, 8, 4, 3, 1, 1, 1]), mode="nearest")
    columnsfiltered = argrelextrema(columns, greater)[0] + 2
    return columnsfiltered


def refactorRows(rowsfiltered):
    rowsdiff = diff(rowsfiltered)
    rowsdiffaverage = (rowsfiltered.max() - rowsfiltered.min()) / (rowsfiltered.shape[0] - 1)

    i = 0
    while (i < rowsdiff.shape[0]):

        dif = rowsdiff[i]

        if ((0.6 * rowsdiffaverage) > dif or dif > (1.6 * rowsdiffaverage)):

            if ((0.6 * rowsdiffaverage) > dif):
                try:
                    newVal = (rowsfiltered[i] + rowsfiltered[i + 1]) / 2
                    rowsfiltered = delete(rowsfiltered, i + 1)
                    rowsfiltered = delete(rowsfiltered, i)
                    rowsfiltered = insert(rowsfiltered, i, int32(newVal))
                    rowsdiff = delete(rowsdiff, i)
                    rowsdiff[i] += dif
                except:
                    continue
                if (i < rowsdiff.shape[0] - 1):
                    i += 1
                continue

            elif (dif > (1.6 * rowsdiffaverage)):
                rowsfiltered = insert(rowsfiltered, i + 1, int32(rowsfiltered[i] + rowsdiffaverage))
                rowsdiff = insert(rowsdiff, i + 1, int32(dif - rowsdiffaverage))

        i += 1

    return rowsfiltered


def calculateRows(transformed):
    transformedsumy = transformed.sum(axis=1)[1:-1].astype("int64")

    tsy2 = convolve1d(convolve1d(transformedsumy, array([1, 1, 1, 3, 5, 8, 4, 3, 1, 1, 1]), mode="nearest"),
                      array([1, 1, 1, 3, 5, 8, 4, 3, 1, 1, 1]), mode="nearest")
    rowsfiltered = argrelextrema(tsy2, greater_equal)[0]

    rowsfiltered = refactorRows(rowsfiltered)
    return rowsfiltered


'''

def safeMakeDir(dir):
    if not path.exists(dir):
        makedirs(dir)
    else:
        stderr.write("Path " + dir + " already exists.\n")
        stderr.flush()

def pdfToImages(source, destFolder, filename, suffix, offset=0):

    safeMakeDir(destFolder[:-1])

    allImages = fitz.open(source)
    for x, page in enumerate(allImages):
        with NamedTemporaryFile(suffix=suffix) as temp:
            page.getPixmap().writePNG(temp.name)
            #scanImage(temp.name, destFolder + filename + str(x + offset) + suffix)
            safeMakeDir(destFolder + "Page " + str(x + offset))
            findLinesandNormalise(temp.name, destFolder + "Page " + str(x + offset) + "/")
    return len(allImages)

def directoryMixedToDirectoryImages(directory, destFolder, filename, suffix):
    countNoImages = 0

    for file in listdir(directory):
        currentFilename = file.lower()

        if currentFilename.endswith(".pdf"):

            countNoImages += pdfToImages(directory + currentFilename, destFolder, filename, suffix, countNoImages)

        elif currentFilename.endswith((".png", ".jpg", ".jpeg")):

            safeMakeDir(destFolder + "Page " + str(countNoImages))

            #scanImage(directory + currentFilename, destFolder + filename + str(countNoImages) + suffix)
            findLinesandNormalise(directory + currentFilename, destFolder + "Page " + str(countNoImages) + "/")
            countNoImages += 1

        else:
            continue
    return

pdfToImages("images/scantest.pdf", "images/pdftest/", "image", ".png")

#directoryMixedToDirectoryImages("images/New Scans Small/", "images/segmentedImagesOut/", "image", ".png")'''
